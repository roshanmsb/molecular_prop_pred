{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Module for lightning datamodules\"\"\"\n",
    "\n",
    "from rdkit.Chem.rdmolfiles import MolFromSmarts\n",
    "from rdkit.Chem import Descriptors\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from deepchem.splits.splitters import RandomStratifiedSplitter, ScaffoldSplitter\n",
    "import deepchem.molnet as dcm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from utils import util_funcs\n",
    "from typing import Callable, Dict, List\n",
    "from rdkit import RDLogger\n",
    "import numpy as np\n",
    "from deepchem.data.datasets import DiskDataset\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class FGRPretrainDataset(Dataset):\n",
    "    \"\"\"Pytorch dataset for pretraining autoencoder\"\"\"\n",
    "\n",
    "    def __init__(self, smiles: List[str], fgroups_list: List[str], tokenizer: Tokenizer) -> None:\n",
    "        \"\"\"Initialize dataset with arguments\n",
    "\n",
    "        Args:\n",
    "            smiles (List[str]): List of SMILES strings\n",
    "            fgroups_list (List[str]): List of functional groups\n",
    "            tokenizer (Tokenizer): Pretrained Tokenizer\n",
    "        \"\"\"\n",
    "        self.smiles = smiles\n",
    "        self.fgroups_list = fgroups_list\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        print(str(smile))\n",
    "        f_g, mfg = util_funcs.smiles2vector_fgr(smile, self.tokenizer, self.fgroups_list)\n",
    "        return f_g, mfg\n",
    "\n",
    "\n",
    "\n",
    "class FGRPretrainDataModule(LightningDataModule):\n",
    "    \"\"\"Lightning Datamodule for pretraining\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        batch_size: int,\n",
    "        num_workers: int,\n",
    "        pin_memory: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize lightning datamodule for pretraining\n",
    "\n",
    "        Args:\n",
    "            root (str): Root data folder\n",
    "            batch_size (int): Batch size\n",
    "            num_workers (int): Number of workers for data loading\n",
    "            pin_memory (bool): Save data in memory\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\")).from_file(\"./data/tokenizer_bpe.json\")\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        df = dd.read_csv(self.root + \"pubchem/pubchem_data_*.csv\")\n",
    "        print(\"Reading SMILES\")\n",
    "        self.train, self.valid = df[\"SMILES\"].random_split((0.9, 0.1), random_state=123)\n",
    "        print(\"Splitting\")\n",
    "        self.train.compute()\n",
    "        self.valid.compute()\n",
    "        fgroups = pd.read_csv(self.root + \"fg.csv\")[\"SMARTS\"].tolist()\n",
    "        self.fgroups_list = [MolFromSmarts(x) for x in fgroups]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_fold = FGRPretrainDataset(self.train, self.fgroups_list, self.tokenizer)\n",
    "        self.val_fold = FGRPretrainDataset(self.valid, self.fgroups_list, self.tokenizer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.train_fold,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.val_fold,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = FGRPretrainDataModule('../datasets/processed/', batch_size=8, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SMILES\n",
      "Splitting\n"
     ]
    }
   ],
   "source": [
    "dat.prepare_data()\n",
    "dat.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = dat.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(lo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SMILES\n"
     ]
    }
   ],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "from rdkit.Chem.rdmolfiles import MolFromSmarts, MolFromSmiles\n",
    "\n",
    "def mol(x):\n",
    "    try:\n",
    "        mols = MolFromSmiles(x)\n",
    "    except:\n",
    "        mols = None\n",
    "    return mols\n",
    "\n",
    "df = dd.read_csv(\"../datasets/processed/\"+ \"pubchem/pubchem_data_*.csv\")\n",
    "print(\"Reading SMILES\")\n",
    "smiles_mol = df[\"SMILES\"].map(lambda x: mol(x))\n",
    "smiles_mol.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:39:06] SMILES Parse Error: syntax error while parsing: CC#\n",
      "[10:39:06] SMILES Parse Error: Failed parsing SMILES 'CC#' for input: 'CC#'\n"
     ]
    }
   ],
   "source": [
    "from rdkit.Chem.rdmolfiles import MolFromSmarts, MolFromSmiles\n",
    "try:\n",
    "    mol = MolFromSmiles('CC#')\n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'SMILES': ['CC#','CC#','CC','CC#']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:42:11] SMILES Parse Error: syntax error while parsing: CC#\n",
      "[10:42:11] SMILES Parse Error: Failed parsing SMILES 'CC#' for input: 'CC#'\n",
      "[10:42:11] SMILES Parse Error: syntax error while parsing: CC#\n",
      "[10:42:11] SMILES Parse Error: Failed parsing SMILES 'CC#' for input: 'CC#'\n",
      "[10:42:11] SMILES Parse Error: syntax error while parsing: CC#\n",
      "[10:42:11] SMILES Parse Error: Failed parsing SMILES 'CC#' for input: 'CC#'\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)['SMILES'].map(lambda x: MolFromSmiles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SMILES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:43:58] SMILES Parse Error: syntax error while parsing: foo\n",
      "[10:43:58] SMILES Parse Error: Failed parsing SMILES 'foo' for input: 'foo'\n",
      "[10:43:58] SMILES Parse Error: syntax error while parsing: foo\n",
      "[10:43:58] SMILES Parse Error: Failed parsing SMILES 'foo' for input: 'foo'\n"
     ]
    }
   ],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "from rdkit.Chem.rdmolfiles import MolFromSmiles\n",
    "import dask.dataframe as dd\n",
    "df = dd.read_csv(\"../datasets/processed/\" + \"pubchem/pubchem_data_*.csv\")\n",
    "print(\"Reading SMILES\")\n",
    "smiles_mol = df[\"SMILES\"].map(lambda x: MolFromSmiles(x))\n",
    "df['mol'] = smiles_mol\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "361a8d57a0e2a78723716f42fcaf9253c19957bfb2980caf149704a44c60f9de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
